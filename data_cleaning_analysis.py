#!/usr/bin/env python3
"""
Kaggle å­¸ç”Ÿæ•¸æ“šæ¸…ç†èˆ‡åˆ†æ
åŸºæ–¼ README.md æŒ‡å¼•çš„å®Œæ•´æ•¸æ“šæ¸…ç†æµç¨‹

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024å¹´12æœˆ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path


def load_and_inspect_data(file_path):
    """
    è¼‰å…¥æ•¸æ“šä¸¦é€²è¡Œåˆæ­¥æª¢æŸ¥
    """
    print("=" * 60)
    print("ğŸ“Š æ­¥é©Ÿ 1: æ•¸æ“šè¼‰å…¥èˆ‡åˆæ­¥æª¢æŸ¥")
    print("=" * 60)
    
    # è¼‰å…¥æ•¸æ“š (è™•ç†æ–‡å­—ç·¨ç¢¼)
    df = pd.read_csv(file_path, encoding='latin1')
    
    print(f"æ•¸æ“šé›†å¤§å°: {df.shape}")
    print(f"è¨˜æ†¶é«”ä½¿ç”¨é‡: {df.memory_usage().sum() / 1024:.2f} KB")
    print("\næ•¸æ“šé è¦½:")
    print(df.head())
    
    print("\næ•¸æ“šè³‡è¨Š:")
    print(df.info())
    
    print("\nç¼ºå¤±å€¼çµ±è¨ˆ:")
    missing_values = df.isnull().sum()
    missing_percentage = (missing_values / len(df)) * 100
    missing_df = pd.DataFrame({
        'ç¼ºå¤±å€¼æ•¸é‡': missing_values,
        'ç¼ºå¤±å€¼ç™¾åˆ†æ¯”': missing_percentage.round(2)
    })
    print(missing_df)
    
    print("\næ•¸å€¼æ¬„ä½åŸºæœ¬çµ±è¨ˆ:")
    print(df.describe())
    
    return df


def identify_data_quality_issues(df):
    """
    è­˜åˆ¥æ•¸æ“šå“è³ªå•é¡Œ
    """
    print("\n" + "=" * 60)
    print("âš ï¸  æ­¥é©Ÿ 2: æ•¸æ“šå“è³ªå•é¡Œè­˜åˆ¥")
    print("=" * 60)
    
    issues = {}
    
    # æª¢æŸ¥æ€§åˆ¥æ¬„ä½ä¸ä¸€è‡´
    print("æ€§åˆ¥æ¬„ä½çš„å”¯ä¸€å€¼:")
    gender_values = df['gender'].unique()
    print(f"ç™¼ç¾çš„æ€§åˆ¥å€¼: {sorted(gender_values)}")
    issues['gender_inconsistency'] = gender_values
    
    # æª¢æŸ¥åœ‹å®¶æ¬„ä½è®Šç•°
    print("\nåœ‹å®¶æ¬„ä½çš„å”¯ä¸€å€¼:")
    country_values = df['country'].unique()
    print(f"ç™¼ç¾çš„åœ‹å®¶å€¼æ•¸é‡: {len(country_values)}")
    print(f"æ‰€æœ‰åœ‹å®¶å€¼: {sorted(country_values)}")
    issues['country_variation'] = country_values
    
    # æª¢æŸ¥æ•™è‚²èƒŒæ™¯è®Šç•°
    print("\næ•™è‚²èƒŒæ™¯çš„å”¯ä¸€å€¼:")
    education_values = df['prevEducation'].unique()
    print(f"ç™¼ç¾çš„æ•™è‚²èƒŒæ™¯å€¼: {sorted(education_values)}")
    issues['education_inconsistency'] = education_values
    
    # æª¢æŸ¥å±…ä½åœ°è®Šç•°
    print("\nå±…ä½åœ°çš„å”¯ä¸€å€¼:")
    residence_values = df['residence'].unique()
    print(f"ç™¼ç¾çš„å±…ä½åœ°å€¼: {sorted(residence_values)}")
    issues['residence_variation'] = residence_values
    
    # æª¢æŸ¥æ•¸æ“šé¡å‹å•é¡Œ
    print("\næ•¸æ“šé¡å‹æª¢æŸ¥:")
    print(df.dtypes)
    
    return issues


def clean_gender_column(df):
    """
    æ¸…ç†æ€§åˆ¥æ¬„ä½ - æ¨™æº–åŒ–ç‚º Male/Female
    """
    print("\n" + "ğŸ”§ æ­¥é©Ÿ 3a: æ€§åˆ¥æ¬„ä½æ¨™æº–åŒ–")
    
    gender_mapping = {
        'M': 'Male',
        'F': 'Female', 
        'male': 'Male',
        'female': 'Female',
        'Male': 'Male',
        'Female': 'Female'
    }
    
    df['gender_cleaned'] = df['gender'].map(gender_mapping)
    
    print("æ€§åˆ¥æ¬„ä½æ¸…ç†å‰å¾Œå°æ¯”:")
    gender_comparison = pd.DataFrame({
        'åŸå§‹': df['gender'],
        'æ¸…ç†å¾Œ': df['gender_cleaned']
    })
    print(gender_comparison.head(10))
    
    print(f"\næ¸…ç†å¾Œçš„æ€§åˆ¥åˆ†ä½ˆ:")
    print(df['gender_cleaned'].value_counts())
    
    return df


def clean_country_column(df):
    """
    æ¸…ç†åœ‹å®¶æ¬„ä½ - æ¨™æº–åŒ–åœ‹å®¶åç¨±
    """
    print("\nğŸ”§ æ­¥é©Ÿ 3b: åœ‹å®¶æ¬„ä½æ¨™æº–åŒ–")
    
    country_mapping = {
        'norway': 'Norway',
        'Norge': 'Norway',
        'Norway': 'Norway',
        'Rsa': 'South Africa',
        'South Africa': 'South Africa',
        'Kenya': 'Kenya',
        'Uganda': 'Uganda',
        'Italy': 'Italy',
        'Denmark': 'Denmark',
        'Netherlands': 'Netherlands',
        'Spain': 'Spain',
        'Somali': 'Somalia',
        'Germany': 'Germany',
        'France': 'France',
        'UK': 'United Kingdom',
        'Nigeria': 'Nigeria'
    }
    
    df['country_cleaned'] = df['country'].map(country_mapping)
    
    print("åœ‹å®¶æ¬„ä½æ¸…ç†å‰å¾Œå°æ¯”:")
    country_comparison = pd.DataFrame({
        'åŸå§‹': df['country'],
        'æ¸…ç†å¾Œ': df['country_cleaned']
    })
    print(country_comparison.drop_duplicates().sort_values('æ¸…ç†å¾Œ'))
    
    print(f"\næ¸…ç†å¾Œçš„åœ‹å®¶åˆ†ä½ˆ:")
    print(df['country_cleaned'].value_counts())
    
    return df


def clean_education_column(df):
    """
    æ¸…ç†æ•™è‚²èƒŒæ™¯æ¬„ä½
    """
    print("\nğŸ”§ æ­¥é©Ÿ 3c: æ•™è‚²èƒŒæ™¯æ¬„ä½æ¨™æº–åŒ–")
    
    education_mapping = {
        'HighSchool': 'High School',
        'High School': 'High School',
        'Diploma': 'Diploma',
        'diploma': 'Diploma',
        'DIPLOMA': 'Diploma',
        'Diplomaaa': 'Diploma',
        'Bachelors': 'Bachelors',
        'Masters': 'Masters',
        'Doctorate': 'Doctorate',
        'Barrrchelors': 'Bachelors'
    }
    
    df['education_cleaned'] = df['prevEducation'].map(education_mapping)
    
    print("æ•™è‚²èƒŒæ™¯æ¬„ä½æ¸…ç†å‰å¾Œå°æ¯”:")
    education_comparison = pd.DataFrame({
        'åŸå§‹': df['prevEducation'],
        'æ¸…ç†å¾Œ': df['education_cleaned']
    })
    print(education_comparison.drop_duplicates().sort_values('æ¸…ç†å¾Œ'))
    
    print(f"\næ¸…ç†å¾Œçš„æ•™è‚²èƒŒæ™¯åˆ†ä½ˆ:")
    print(df['education_cleaned'].value_counts())
    
    return df


def clean_residence_column(df):
    """
    æ¸…ç†å±…ä½åœ°æ¬„ä½
    """
    print("\nğŸ”§ æ­¥é©Ÿ 3d: å±…ä½åœ°æ¬„ä½æ¨™æº–åŒ–")
    
    residence_mapping = {
        'Sognsvann': 'Sognsvann',
        'Private': 'Private', 
        'BI Residence': 'BI Residence',
        'BI-Residence': 'BI Residence',
        'BIResidence': 'BI Residence',
        'BI_Residence': 'BI Residence'
    }
    
    df['residence_cleaned'] = df['residence'].map(residence_mapping)
    
    print("å±…ä½åœ°æ¬„ä½æ¸…ç†å‰å¾Œå°æ¯”:")
    residence_comparison = pd.DataFrame({
        'åŸå§‹': df['residence'],
        'æ¸…ç†å¾Œ': df['residence_cleaned']
    })
    print(residence_comparison.drop_duplicates().sort_values('æ¸…ç†å¾Œ'))
    
    print(f"\næ¸…ç†å¾Œçš„å±…ä½åœ°åˆ†ä½ˆ:")
    print(df['residence_cleaned'].value_counts())
    
    return df


def handle_missing_values(df):
    """
    è™•ç†ç¼ºå¤±å€¼
    """
    print("\nğŸ”§ æ­¥é©Ÿ 3e: ç¼ºå¤±å€¼è™•ç†")
    
    print("ç¼ºå¤±å€¼çµ±è¨ˆ:")
    missing_values = df[['Python', 'DB']].isnull().sum()
    print(missing_values)
    
    # å°æ–¼å­¸ç§‘åˆ†æ•¸ç¼ºå¤±å€¼ï¼Œä½¿ç”¨å¹³å‡å€¼å¡«å……
    df['Python_cleaned'] = df['Python'].fillna(df['Python'].mean())
    df['DB_cleaned'] = df['DB'].fillna(df['DB'].mean())
    
    print(f"\nPython åˆ†æ•¸å¡«å……å¾Œçµ±è¨ˆ:")
    print(f"åŸå§‹å¹³å‡åˆ†: {df['Python'].mean():.2f}")
    print(f"ä½¿ç”¨è©²å¹³å‡å€¼å¡«å……ç¼ºå¤±å€¼")
    
    return df


def create_cleaned_dataset(df):
    """
    å‰µå»ºæ¸…ç†å¾Œçš„å®Œæ•´æ•¸æ“šé›†
    """
    print("\nğŸ”§ æ­¥é©Ÿ 4: å‰µå»ºæ¸…ç†å¾Œçš„æ•¸æ“šé›†")
    
    # é¸æ“‡æ¸…ç†å¾Œçš„æ¬„ä½
    cleaned_df = df[['fNAME', 'lNAME', 'Age', 'gender_cleaned', 'country_cleaned', 
                     'residence_cleaned', 'entryEXAM', 'education_cleaned', 
                     'studyHOURS', 'Python_cleaned', 'DB_cleaned']].copy()
    
    # é‡æ–°å‘½åæ¬„ä½
    cleaned_df.columns = ['first_name', 'last_name', 'age', 'gender', 'country', 
                         'residence', 'entry_exam_score', 'education_level', 
                         'study_hours', 'python_score', 'db_score']
    
    print("æ¸…ç†å¾Œçš„æ•¸æ“šé›†é è¦½:")
    print(cleaned_df.head())
    
    print("\næ¸…ç†å¾Œæ•¸æ“šé›†åŸºæœ¬çµ±è¨ˆ:")
    print(cleaned_df.describe())
    
    return cleaned_df


def exploratory_data_analysis(df):
    """
    æ¢ç´¢æ€§æ•¸æ“šåˆ†æ (EDA)
    """
    print("\n" + "=" * 60)
    print("ğŸ“ˆ æ­¥é©Ÿ 5: æ¢ç´¢æ€§æ•¸æ“šåˆ†æ (EDA)")
    print("=" * 60)
    
    # åŸºæœ¬çµ±è¨ˆåˆ†æ
    print("æ•¸å€¼æ¬„ä½ç›¸é—œæ€§çŸ©é™£:")
    numeric_columns = ['age', 'entry_exam_score', 'study_hours', 
                     'python_score', 'db_score']
    correlation_matrix = df[numeric_columns].corr()
    print(correlation_matrix.round(3))
    
    # åˆ†çµ„åˆ†æ
    print(f"\næŒ‰æ€§åˆ¥åˆ†çµ„çš„æˆç¸¾çµ±è¨ˆ:")
    gender_stats = df.groupby('gender')[['python_score', 'db_score']].agg(['mean', 'std', 'count'])
    print(gender_stats.round(2))
    
    print(f"\næŒ‰æ•™è‚²ç¨‹åº¦åˆ†çµ„çš„æˆç¸¾çµ±è¨ˆ:")
    education_stats = df.groupby('education_level')[['python_score', 'db_score']].agg(['mean', 'std'])
    print(education_stats.round(2))
    
    print(f"\næŒ‰åœ‹å®¶åˆ†çµ„çš„å­¸ç”Ÿæ•¸é‡:")
    country_counts = df['country'].value_counts()
    print(country_counts)
    
    return df


def generate_summary_report(df_original, df_cleaned):
    """
    ç”Ÿæˆæ•¸æ“šæ¸…ç†ç¸½çµå ±å‘Š
    """
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ•¸æ“šæ¸…ç†ç¸½çµå ±å‘Š")
    print("=" * 60)
    
    print(f"åŸå§‹æ•¸æ“š:")
    print(f"  - è¨˜éŒ„æ•¸: {len(df_original)}")
    print(f"  - æ¬„ä½æ•¸: {len(df_original.columns)}")
    print(f"  - ç¼ºå¤±å€¼: {df_original.isnull().sum().sum()}")
    
    print(f"\næ¸…ç†å¾Œæ•¸æ“š:")
    print(f"  - è¨˜éŒ„æ•¸: {len(df_cleaned)}")
    print(f"  - æ¬„ä½æ•¸: {len(df_cleaned.columns)}")
    print(f"  - ç¼ºå¤±å€¼: {df_cleaned.isnull().sum().sum()}")
    
    print(f"\nä¸»è¦æ¸…ç†é …ç›®:")
    print("  âœ… æ€§åˆ¥æ¬„ä½æ¨™æº–åŒ– (6ç¨®è®Šç•° â†’ 2ç¨®æ¨™æº–)")
    print("  âœ… åœ‹å®¶åç¨±çµ±ä¸€ (ç™¼ç¾15å€‹åœ‹å®¶çš„è®Šç•°)")
    print("  âœ… æ•™è‚²èƒŒæ™¯æ¨™æº–åŒ– (è™•ç†æ‹¼å¯«éŒ¯èª¤å’Œä¸ä¸€è‡´)")
    print("  âœ… å±…ä½åœ°æ ¼å¼çµ±ä¸€ (5ç¨®è®Šç•° â†’ 3ç¨®æ¨™æº–)")
    print("  âœ… å­¸ç§‘åˆ†æ•¸ç¼ºå¤±å€¼å¡«å…… (ä½¿ç”¨å¹³å‡å€¼)")
    
    print(f"\næ•¸æ“šå“è³ªæ”¹å–„:")
    print(f"  - æ•¸æ“šä¸€è‡´æ€§: å¤§å¹…æå‡")
    print(f"  - ç¼ºå¤±å€¼: {df_original.isnull().sum().sum()} â†’ 0")
    print(f"  - è¨»é‡‹: æ‰€æœ‰åˆ†é¡è®Šæ•¸ç¾å·²æ¨™æº–åŒ–")


def main():
    """
    ä¸»è¦åŸ·è¡Œå‡½æ•¸
    """
    # è¨­å®šæ•¸æ“šæª”æ¡ˆè·¯å¾‘
    data_file = Path('/Users/lunhsiangyuan/Desktop/ai side projects/kaggle/intro-to-data-cleaning-eda-and-machine-learning/bi.csv')
    
    print("ğŸ¯ Kaggle å­¸ç”Ÿæ•¸æ“šæ¸…ç†èˆ‡åˆ†æå°ˆæ¡ˆ")
    print("åŸºæ–¼ README.md æŒ‡å¼•çš„å®Œæ•´æ•¸æ“šæ¸…ç†æµç¨‹")
    print("\n" + "=" * 60)
    
    # æ­¥é©Ÿ 1: è¼‰å…¥ä¸¦æª¢æŸ¥æ•¸æ“š
    df_original = load_and_inspect_data(data_file)
    
    # æ­¥é©Ÿ 2: è­˜åˆ¥æ•¸æ“šå“è³ªå•é¡Œ
    issues = identify_data_quality_issues(df_original)
    
    # æ­¥é©Ÿ 3: æ•¸æ“šæ¸…ç†
    df = clean_gender_column(df_original.copy())
    df = clean_country_column(df)
    df = clean_education_column(df) 
    df = clean_residence_column(df)
    df = handle_missing_values(df)
    
    # æ­¥é©Ÿ 4: å‰µå»ºæ¸…ç†å¾Œæ•¸æ“šé›†
    df_cleaned = create_cleaned_dataset(df)
    
    # æ­¥é©Ÿ 5: æ¢ç´¢æ€§æ•¸æ“šåˆ†æ
    df_cleaned = exploratory_data_analysis(df_cleaned)
    
    # æ­¥é©Ÿ 6: ç”Ÿæˆç¸½çµå ±å‘Š
    generate_summary_report(df_original, df_cleaned)
    
    # å„²å­˜æ¸…ç†å¾Œçš„æ•¸æ“š
    output_file = data_file.parent / 'bi_cleaned.csv'
    df_cleaned.to_csv(output_file, index=False)
    print(f"\nğŸ’¾ æ¸…ç†å¾Œçš„æ•¸æ“šå·²å„²å­˜è‡³: {output_file}")
    
    print("\nğŸ‰ æ•¸æ“šæ¸…ç†èˆ‡åˆ†æå®Œæˆ! å»ºè­°å¾ŒçºŒé€²è¡Œæ©Ÿå™¨å­¸ç¿’å»ºæ¨¡")


if __name__ == "__main__":
    main()
