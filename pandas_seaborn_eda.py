#!/usr/bin/env python3
"""
Pandas + Seaborn EDA åˆ†æ
ä½¿ç”¨åŸºç¤å·¥å…·é€²è¡Œå…¨é¢çš„æ¢ç´¢æ€§æ•¸æ“šåˆ†æ

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024å¹´12æœˆ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# è¨­ç½®ä¸­æ–‡å­—é«”å’Œæ¨£å¼
plt.rcParams['font.family'] = ['Arial Unicode MS', 'DejaVu Sans', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("tab10")


def load_and_explore_data(file_path):
    """
    è¼‰å…¥æ•¸æ“šä¸¦é€²è¡ŒåŸºæœ¬æ¢ç´¢
    """
    print("=" * 60)
    print("ğŸ“Š Kaggle å­¸ç”Ÿæ•¸æ“š - Pandas + Seaborn EDA åˆ†æ")
    print("=" * 60)
    
    # è¼‰å…¥æ•¸æ“š
    df = pd.read_csv(file_path, encoding='latin1')
    
    print(f"\nğŸ“ˆ æ•¸æ“šé›†åŸºæœ¬è³‡è¨Š:")
    print(f"  - æ•¸æ“šç¶­åº¦: {df.shape}")
    print(f"  - æ¬„ä½æ•¸: {len(df.columns)}")
    print(f"  - è¨˜æ†¶é«”ä½¿ç”¨é‡: {df.memory_usage().sum() / 1024:.2f} KB")
    
    print(f"\nğŸ” æ¬„ä½è³‡è¨Š:")
    for i, col in enumerate(df.columns, 1):
        dtype = df[col].dtype
        null_count = df[col].isnull().sum()
        print(f"  {i:2d}. {col:12s} - {str(dtype):8s} - ç¼ºå¤±å€¼: {null_count}")
    
    return df


def generate_basic_statistics(df):
    """
    ç”ŸæˆåŸºæœ¬çµ±è¨ˆè³‡è¨Š
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š åŸºæœ¬çµ±è¨ˆåˆ†æ")
    print("=" * 60)
    
    # æ•¸å€¼åˆ—æè¿°çµ±è¨ˆ
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    print(f"\nğŸ“ˆ æ•¸å€¼æ¬„ä½æè¿°çµ±è¨ˆ:")
    print(df[numeric_cols].describe().round(2))
    
    # åˆ†é¡è®Šé‡çµ±è¨ˆ
    categorical_cols = df.select_dtypes(include=['object']).columns
    print(f"\nğŸ“‹ åˆ†é¡è®Šé‡çµ±è¨ˆ:")
    
    for col in categorical_cols:
        if col not in ['fNAME', 'lNAME']:  # æ’é™¤å§“åå­—æ®µ
            print(f"\n{col}:")
            value_counts = df[col].value_counts().head(10)
            for value, count in value_counts.items():
                percentage = (count / len(df)) * 100
                print(f"  {str(value):15s}: {count:2d}äºº ({percentage:4.1f}%)")
    
    return numeric_cols, categorical_cols


def create_comprehensive_visualizations(df):
    """
    å‰µå»ºå…¨é¢çš„è¦–è¦ºåŒ–åœ–è¡¨
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š å‰µå»ºå…¨æ–¹ä½è¦–è¦ºåŒ–åœ–è¡¨")
    print("=" * 60)
    
    # è¨­ç½®å¤§å‹åœ–è¡¨
    fig = plt.figure(figsize=(20, 24))
    
    # 1. å¹´é½¡åˆ†ä½ˆç›´æ–¹åœ–
    plt.subplot(4, 4, 1)
    sns.histplot(data=df, x='Age', bins=15, kde=True, alpha=0.7)
    plt.title('å¹´é½¡åˆ†ä½ˆç›´æ–¹åœ–', fontsize=14, fontweight='bold')
    plt.xlabel('å¹´é½¡')
    plt.ylabel('äººæ•¸')
    
    # 2. Python æˆç¸¾åˆ†ä½ˆ
    plt.subplot(4, 4, 2)
    sns.histplot(data=df, x='Python', bins=12, kde=True, alpha=0.7, color='skyblue')
    plt.title('Python æˆç¸¾åˆ†ä½ˆ', fontsize=14, fontweight='bold')
    plt.xlabel('åˆ†æ•¸')
    plt.ylabel('äººæ•¸')
    
    # 3. DB æˆç¸¾åˆ†ä½ˆ
    plt.subplot(4, 4, 3)
    sns.histplot(data=df, x='DB', bins=12, kde=True, alpha=0.7, color='lightcoral')
    plt.title('DB æˆç¸¾åˆ†ä½ˆ', fontsize=14, fontweight='bold')
    plt.xlabel('åˆ†æ•¸')
    plt.ylabel('äººæ•¸')
    
    # 4. å­¸ç¿’æ™‚æ•¸åˆ†ä½ˆ
    plt.subplot(4, 4, 4)
    sns.histplot(data=df, x='studyHOURS', bins=10, kde=True, alpha=0.7, color='lightgreen')
    plt.title('å­¸ç¿’æ™‚æ•¸åˆ†ä½ˆ', fontsize=14, fontweight='bold')
    plt.xlabel('æ™‚æ•¸')
    plt.ylabel('äººæ•¸')
    
    # 5. æ€§åˆ¥åˆ†ä½ˆåœ“é¤…åœ–
    plt.subplot(4, 4, 5)
    gender_counts = df['gender'].value_counts()
    colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#ff99cc']
    plt.pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', 
            colors=colors[:len(gender_counts)])
    plt.title('æ€§åˆ¥åˆ†ä½ˆ', fontsize=14, fontweight='bold')
    
    # 6. åœ‹å®¶åˆ†ä½ˆæŸ±ç‹€åœ– (å‰10å)
    plt.subplot(4, 4, 6)
    top_countries = df['country'].value_counts().head(10)
    bars = plt.bar(range(len(top_countries)), top_countries.values, 
                   color=plt.cm.Set3(np.linspace(0, 1, len(top_countries))))
    plt.xticks(range(len(top_countries)), top_countries.index, rotation=45)
    plt.title('åœ‹å®¶å­¸ç”Ÿæ•¸çµ±è¨ˆ (å‰10å)', fontsize=14, fontweight='bold')
    plt.ylabel('äººæ•¸')
    
    # 7. å±…ä½åœ°åˆ†ä½ˆ
    plt.subplot(4, 4, 7)
    residence_counts = df['residence'].value_counts()
    sns.barplot(x=residence_counts.index, y=residence_counts.values, palette='viridis')
    plt.xticks(rotation=15)
    plt.title('å±…ä½åœ°åˆ†ä½ˆ', fontsize=14, fontweight='bold')
    plt.ylabel('äººæ•¸')
    
    # 8. æ•™è‚²ç¨‹åº¦åˆ†ä½ˆ
    plt.subplot(4, 4, 8)
    education_counts = df['prevEducation'].value_counts()
    sns.barplot(x=education_counts.index, y=education_counts.values, palette='coolwarm')
    plt.xticks(rotation=15)
    plt.title('æ•™è‚²ç¨‹åº¦åˆ†ä½ˆ', fontsize=14, fontweight='bold')
    plt.ylabel('äººæ•¸')
    
    # 9. å­¸ç¿’æ™‚é–“ vs Pythonæˆç¸¾æ•£é»åœ–
    plt.subplot(4, 4, 9)
    sns.scatterplot(data=df, x='studyHOURS', y='Python', alpha=0.7)
    plt.title('å­¸ç¿’æ™‚é–“ vs Pythonæˆç¸¾', fontsize=14, fontweight='bold')
    plt.xlabel('å­¸ç¿’æ™‚æ•¸')
    plt.ylabel('Python åˆ†æ•¸')
    
    # 10. Python vs DB æˆç¸¾æ•£é»åœ–
    plt.subplot(4, 4, 10)
    sns.scatterplot(data=df, x='Python', y='DB', alpha=0.7, color='purple')
    plt.title('Python vs DB æˆç¸¾é—œä¿‚', fontsize=14, fontweight='bold')
    plt.xlabel('Python åˆ†æ•¸')
    plt.ylabel('DB åˆ†æ•¸')
    
    # 11. ç®±ç·šåœ–: ä¸åŒæ€§åˆ¥çš„Pythonæˆç¸¾
    plt.subplot(4, 4, 11)
    sns.boxplot(data=df, x='gender', y='Python')
    plt.title('ä¸åŒæ€§åˆ¥çš„Pythonæˆç¸¾', fontsize=14, fontweight='bold')
    plt.xticks(rotation=15)
    plt.ylabel('Python åˆ†æ•¸')
    
    # 12. ç®±ç·šåœ–: ä¸åŒä½å®¿é¡å‹çš„æˆç¸¾æ¯”è¼ƒ
    plt.subplot(4, 4, 12)
    sns.boxplot(data=df, x='residence', y='Python')
    plt.title('ä¸åŒä½å®¿é¡å‹çš„Pythonæˆç¸¾', fontsize=14, fontweight='bold')
    plt.xticks(rotation=15)
    plt.ylabel('Python åˆ†æ•¸')
    
    # 13. å…¥å­¸è€ƒè©¦èˆ‡æˆç¸¾é—œä¿‚
    plt.subplot(4, 4, 13)
    sns.scatterplot(data=df, x='entryEXAM', y='Python', alpha=0.7, color='orange')
    plt.title('å…¥å­¸è€ƒè©¦ vs Pythonæˆç¸¾', fontsize=14, fontweight='bold')
    plt.xlabel('å…¥å­¸è€ƒè©¦åˆ†æ•¸')
    plt.ylabel('Python åˆ†æ•¸')
    
    # 14. å¹´é½¡èˆ‡æˆç¸¾é—œä¿‚
    plt.subplot(4, 4, 14)
    sns.scatterplot(data=df, x='Age', y='Python', alpha=0.7, color='teal')
    plt.title('å¹´é½¡ vs Pythonæˆç¸¾', fontsize=14, fontweight='bold')
    plt.xlabel('å¹´é½¡')
    plt.ylabel('Python åˆ†æ•¸')
    
    # 15. ä¸åŒæ•™è‚²ç¨‹åº¦çš„å¹³å‡æˆç¸¾
    plt.subplot(4, 4, 15)
    education_scores = df.groupby('prevEducation')['Python'].mean().sort_values(ascending=False)
    sns.barplot(x=education_scores.index, y=education_scores.values, palette='Set2')
    plt.xticks(rotation=15)
    plt.title('ä¸åŒæ•™è‚²ç¨‹åº¦çš„å¹³å‡Pythonæˆç¸¾', fontsize=14, fontweight='bold')
    plt.ylabel('å¹³å‡ Python åˆ†æ•¸')
    
    # 16. æ•£é»åœ–çŸ©é™£ç¤ºä¾‹
    plt.subplot(4, 4, 16)
    # é¸æ“‡éƒ¨åˆ†è®Šé‡å‰µå»ºç›¸é—œæ€§æ•£é»åœ–
    test_df = df[['studyHOURS', 'Python', 'DB']].dropna()
    plt.scatter(test_df['studyHOURS'], test_df['DB'], alpha=0.6, color='red')
    plt.title('å­¸ç¿’æ™‚é–“ vs DBæˆç¸¾', fontsize=14, fontweight='bold')
    plt.xlabel('å­¸ç¿’æ™‚æ•¸')
    plt.ylabel('DB åˆ†æ•¸')
    
    plt.tight_layout()
    
    # å„²å­˜åœ–è¡¨
    output_file = Path('/Users/lunhsiangyuan/Desktop/ai side projects/kaggle/doc/pandas_seaborn_eda_analysis.png')
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"âœ… åœ–è¡¨å·²å„²å­˜è‡³: {output_file}")
    
    return df


def correlation_analysis(df):
    """
    ç›¸é—œæ€§åˆ†æ
    """
    print("\n" + "=" * 60)
    print("ğŸ”— ç›¸é—œæ€§åˆ†æ")
    print("=" * 60)
    
    # é¸å–æ•¸å€¼è®Šé‡é€²è¡Œç›¸é—œæ€§åˆ†æ
    numeric_vars = ['Age', 'entryEXAM', 'studyHOURS', 'Python', 'DB']
    correlation_matrix = df[numeric_vars].corr()
    
    print("ğŸ“Š ç›¸é—œæ€§çŸ©é™£:")
    print(correlation_matrix.round(3))
    
    # å‰µå»ºç›¸é—œæ€§ç†±åœ–
    plt.figure(figsize=(10, 8))
    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
    sns.heatmap(correlation_matrix, 
                mask=mask,
                annot=True, 
                cmap='RdYlBu_r', 
                center=0,
                square=True,
                fmt='.3f',
                cbar_kws={'shrink': 0.8})
    plt.title('æ•¸å€¼è®Šé‡ç›¸é—œæ€§ç†±åœ–', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # å„²å­˜ç›¸é—œæ€§åœ–è¡¨
    corr_file = Path('/Users/lunhsiangyuan/Desktop/ai side projects/kaggle/doc/correlation_heatmap_seaborn.png')
    plt.savefig(corr_file, dpi=300, bbox_inches='tight')
    print(f"âœ… ç›¸é—œæ€§ç†±åœ–å·²å„²å­˜è‡³: {corr_file}")
    
    # è©³ç´°ç›¸é—œæ€§åˆ†æ
    print(f"\nğŸ” é‡è¦ç›¸é—œæ€§ç™¼ç¾:")
    
    # æ‰¾å‡ºå¼·ç›¸é—œæ€§ (|r| > 0.5)
    strong_corr_pairs = []
    for i in range(len(correlation_matrix.columns)):
        for j in range(i+1, len(correlation_matrix.columns)):
            corr_value = correlation_matrix.iloc[i, j]
            if abs(corr_value) > 0.5:
                strong_corr_pairs.append((
                    correlation_matrix.columns[i], 
                    correlation_matrix.columns[j], 
                    corr_value
                ))
    
    if strong_corr_pairs:
        print("  ğŸ¯ å¼·ç›¸é—œæ€§é…å° (|r| > 0.5):")
        for var1, var2, corr in strong_corr_pairs:
            print(f"    - {var1} â†” {var2}: {corr:.3f}")
    
    return correlation_matrix


def advanced_analysis(df):
    """
    é€²éšåˆ†æ
    """
    print("\n" + "=" * 60)
    print("ğŸ¯ é€²éšåˆ†ææ´å¯Ÿ")
    print("=" * 60)
    
    # 1. æˆç¸¾åˆ†ç´šåˆ†æ
    print("ğŸ“Š æˆç¸¾åˆ†ç´šåˆ†æ:")
    
    # Python æˆç¸¾åˆ†ç´š
    df['Python_grade'] = pd.cut(df['Python'], 
                                bins=[0, 60, 70, 80, 90, 100], 
                                labels=['ä¸åŠæ ¼', 'åŠæ ¼', 'åŠæ ¼+', 'è‰¯å¥½', 'å„ªç§€'])
    
    python_grades = df['Python_grade'].value_counts().sort_index()
    print("\n  Python æˆç¸¾åˆ†ç´š:")
    for grade, count in python_grades.items():
        percentage = (count / len(df.dropna(subset=['Python']))) * 100
        print(f"    {grade}: {count}äºº ({percentage:.1f}%)")
    
    # 2. å­¸ç¿’æ•ˆç‡åˆ†æ (å­¸ç¿’æ™‚é–“ vs æˆç¸¾)
    print(f"\nğŸ“ˆ å­¸ç¿’æ•ˆç‡åˆ†æ:")
    
    # è¨ˆç®—å­¸ç¿’æ•ˆç‡ (æˆç¸¾/å­¸ç¿’æ™‚é–“)
    df['study_efficiency'] = df['Python'] / df['studyHOURS'] * 100
    efficiency_stats = df['study_efficiency'].describe()
    
    print(f"  å­¸ç¿’æ•ˆç‡ (Pythonåˆ†æ•¸/å­¸ç¿’æ™‚æ•¸):")
    print(f"    - å¹³å‡æ•ˆç‡: {efficiency_stats['mean']:.2f}")
    print(f"    - æœ€é«˜æ•ˆç‡: {efficiency_stats['max']:.2f}")
    print(f"    - æœ€ä½æ•ˆç‡: {efficiency_stats['min']:.2f}")
    
    # æ•ˆç‡æœ€é«˜çš„å­¸ç”Ÿ
    top_efficiency = df.nlargest(3, 'study_efficiency')
    print(f"\n  æ•ˆç‡æœ€é«˜çš„3åå­¸ç”Ÿ:")
    for idx, row in top_efficiency.iterrows():
        print(f"    - {row['fNAME']} {row['lNAME']}: Python={row['Python']}, æ•ˆç‡={row['study_efficiency']:.2f}")
    
    # 3. ä½å®¿é¡å‹å°å­¸æ¥­å½±éŸ¿åˆ†æ
    print(f"\nğŸ  ä½å®¿é¡å‹å°å­¸æ¥­å½±éŸ¿:")
    
    residence_analysis = df.groupby('residence').agg({
        'Python': ['mean', 'std', 'count'],
        'studyHOURS': 'mean',
        'Age': 'mean'
    }).round(2)
    
    print(residence_analysis)
    
    # 4. å¹´é½¡æ®µåˆ†æ
    print(f"\nğŸ‘¥ å¹´é½¡æ®µåˆ†æ:")
    
    df['age_group'] = pd.cut(df['Age'],
                             bins=[0, 25, 35, 45, 100],
                             labels=['å¹´è¼•(21-25)', 'ä¸­é’å¹´(26-35)', 'ä¸­å¹´(36-45)', 'è³‡æ·±(46+)'])
    
    age_group_stats = df.groupby('age_group')['Python'].agg(['mean', 'count']).round(2)
    print(age_group_stats)
    
    return df


def create_detailed_report(df):
    """
    ç”Ÿæˆè©³ç´°å ±å‘Š
    """
    print("\n" + "=" * 60)
    print("ğŸ“‹ ç¶œåˆåˆ†æå ±å‘Š")
    print("=" * 60)
    
    print(f"ğŸ¯ æ•¸æ“šé›†æ¦‚è¦½:")
    print(f"  - ç¸½å­¸ç”Ÿæ•¸: {len(df)}")
    print(f"  - æ¶µè“‹åœ‹å®¶: {df['country'].nunique()}å€‹")
    print(f"  - å¹´é½¡ç¯„åœ: {df['Age'].min()}-{df['Age'].max()}æ­²")
    print(f"  - å¹³å‡å¹´é½¡: {df['Age'].mean():.1f}æ­²")
    
    print(f"\nğŸ“Š å­¸æ¥­è¡¨ç¾æ¦‚æ³:")
    print(f"  - Python å¹³å‡æˆç¸¾: {df['Python'].mean():.1f}åˆ†")
    print(f"  - DB å¹³å‡æˆç¸¾: {df['DB'].mean():.1f}åˆ†")
    print(f"  - å¹³å‡å­¸ç¿’æ™‚æ•¸: {df['studyHOURS'].mean():.1f}å°æ™‚")
    print(f"  - å¹³å‡å…¥å­¸åˆ†æ•¸: {df['entryEXAM'].mean():.1f}åˆ†")
    
    print(f"\nğŸ” é‡è¦ç™¼ç¾:")
    print(f"  - æœ€é«˜åˆ†å­¸ç”Ÿ: {df.loc[df['Python'].idxmax(), 'fNAME']} {df.loc[df['Python'].idxmax(), 'lNAME']} ({df['Python'].max()}åˆ†)")
    print(f"  - å­¸ç¿’æ™‚é–“æœ€é•·: {df['studyHOURS'].max()}å°æ™‚")
    print(f"  - æœ€å¹´è¼•å­¸ç”Ÿ: {df['Age'].min()}æ­²")
    
    print(f"\nğŸ“ æ•™è‚²èƒŒæ™¯åˆ†æ:")
    education_summary = df['prevEducation'].value_counts()
    for edu, count in education_summary.items():
        percentage = (count / len(df)) * 100
        print(f"  - {edu}: {count}äºº ({percentage:.1f}%)")
    
    print(f"\nğŸŒ åœ‹éš›å­¸ç”Ÿåˆ†æ:")
    print(f"  - æŒªå¨å­¸ç”Ÿ: {df[df['country'].str.contains('Norway|norway|Norge', na=False)].shape[0]}äºº")
    print(f"  - éæ´²å­¸ç”Ÿ: {df[df['country'].isin(['Kenya', 'Uganda', 'Nigeria', 'South Africa', 'Rsa'])].shape[0]}äºº")
    print(f"  - æ­æ´²å­¸ç”Ÿ: {df[df['country'].isin(['Germany', 'Denmark', 'Netherlands', 'Italy', 'France', 'Spain', 'UK'])].shape[0]}äºº")
    
    print(f"\nğŸ’¡ å»ºè­°:")
    print(f"  âœ“ æ•¸æ“šå“è³ªå„ªç§€ï¼Œåƒ…2å€‹Pythonæˆç¸¾ç¼ºå¤±å€¼")
    print(f"  âœ“ å­¸ç¿’æ™‚é–“èˆ‡Pythonæˆç¸¾å‘ˆå¼·ç›¸é—œ")
    print(f"  âœ“ å¯å»ºç«‹å¤šç¨®æ©Ÿå™¨å­¸ç¿’æ¨¡å‹é€²è¡Œæˆç¸¾é æ¸¬")
    print(f"  âœ“ å»ºè­°é€²è¡Œä½å®¿é¡å‹èˆ‡å­¸ç¿’æ•ˆç‡çš„é€²ä¸€æ­¥åˆ†æ")


def main():
    """
    ä¸»è¦åŸ·è¡Œå‡½æ•¸
    """
    # è¨­å®šæ•¸æ“šæª”æ¡ˆè·¯å¾‘
    data_file = Path('/Users/lunhsiangyuan/Desktop/ai side projects/kaggle/intro-to-data-cleaning-eda-and-machine-learning/bi.csv')
    
    try:
        # 1. è¼‰å…¥å’Œæ¢ç´¢æ•¸æ“š
        df = load_and_explore_data(data_file)
        
        # 2. åŸºæœ¬çµ±è¨ˆåˆ†æ
        numeric_cols, categorical_cols = generate_basic_statistics(df)
        
        # 3. è¦–è¦ºåŒ–åˆ†æ
        df = create_comprehensive_visualizations(df)
        
        # 4. ç›¸é—œæ€§åˆ†æ
        correlation_matrix = correlation_analysis(df)
        
        # 5. é€²éšåˆ†æ
        df = advanced_analysis(df)
        
        # 6. ç”Ÿæˆè©³ç´°å ±å‘Š
        create_detailed_report(df)
        
        print("\nğŸ‰ Pandas + Seaborn EDA åˆ†æå®Œæˆ!")
        
        print("\nğŸ“ ç”Ÿæˆçš„æª”æ¡ˆ:")
        print("  - pandas_seaborn_eda_analysis.png: å…¨æ–¹ä½è¦–è¦ºåŒ–åœ–è¡¨")
        print("  - correlation_heatmap_seaborn.png: ç›¸é—œæ€§ç†±åœ–")
        
    except Exception as e:
        print(f"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
